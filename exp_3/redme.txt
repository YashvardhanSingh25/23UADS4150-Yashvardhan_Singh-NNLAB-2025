# README: Evaluating Perceptron Performance with Linear and Sigmoid Activation

## What is a Perceptron?
A Perceptron is a simple machine learning model that learns from examples and makes predictions. It can be used for:
- **Regression (predicting numbers, like house prices)** using a **Linear activation function**
- **Classification (deciding categories, like cat or dog)** using a **Sigmoid activation function**

---

## What is Activation Function?
An activation function helps the perceptron decide what output to give.
- **Linear Activation**: Used for regression problems where we predict numbers.
- **Sigmoid Activation**: Used for binary classification problems where the output is 0 or 1 (yes or no).

---

## How Does This Work?
1. **Takes Inputs**: The perceptron gets data (like weight, height, etc.).
2. **Applies Weights**: It multiplies each input by a weight (importance value).
3. **Calculates the Sum**: Adds up all weighted inputs.
4. **Applies Activation Function**: Uses Linear for regression or Sigmoid for classification.
5. **Trains Using Gradient Descent**: Adjusts weights to improve accuracy.

---

## Code Explanation

### Step 1: Import Required Libraries
We use NumPy for calculations and Pandas for handling data.
```python
import numpy as np
import pandas as pd
```

### Step 2: Define the Perceptron Class
This class stores:
- **Weights** (which change over time)
- **Learning Rate** (how fast it learns)
- **Epochs** (how many times it trains on data)
- **Activation Function** (Linear for regression, Sigmoid for classification)

```python
class Perceptron:
    def __init__(self, input_size, learning_rate=0.01, epochs=100, activation='linear'):
        self.weights = np.zeros(input_size + 1)  # +1 for bias
        self.learning_rate = learning_rate
        self.epochs = epochs
        self.activation = activation
```

### Step 3: Activation Function
This function decides how to process inputs.
```python
    def activation_function(self, x):
        if self.activation == 'linear':
            return x
        elif self.activation == 'sigmoid':
            return 1 / (1 + np.exp(-x))
```

### Step 4: Prediction Function
This function calculates the weighted sum and applies the activation function.
```python
    def predict(self, x):
        x = np.insert(x, 0, 1)  # Insert bias term
        return self.activation_function(np.dot(self.weights, x))
```

### Step 5: Training Function (Using Gradient Descent)
This helps the perceptron learn by adjusting weights based on errors.
```python
    def train(self, X, y):
        X = np.insert(X, 0, 1, axis=1)  # Insert bias term
        for _ in range(self.epochs):
            gradient = np.zeros_like(self.weights)
            for i in range(len(y)):
                prediction = self.activation_function(np.dot(self.weights, X[i]))
                error = y[i] - prediction
                gradient += error * X[i]
            self.weights += self.learning_rate * gradient / len(y)
```

### Step 6: Evaluating Performance
We train and test the perceptron on **regression and classification** problems.
```python
if __name__ == "__main__":
    # Regression (Linear Activation)
    data_reg = pd.DataFrame({
        'x1': [1, 2, 3, 4, 5],
        'x2': [2, 3, 4, 5, 6],
        'y': [2.2, 2.8, 3.6, 4.5, 5.1]
    })
    X_reg = data_reg[['x1', 'x2']].values
    y_reg = data_reg['y'].values
    
    perceptron_reg = Perceptron(input_size=2, activation='linear')
    perceptron_reg.train(X_reg, y_reg)
    
    print("Regression Predictions:")
    for sample in X_reg:
        print(f"Input: {sample}, Predicted: {perceptron_reg.predict(sample)}")
    
    # Classification (Sigmoid Activation)
    data_clf = pd.DataFrame({
        'x1': [0, 0, 1, 1],
        'x2': [0, 1, 0, 1],
        'y': [0, 0, 0, 1]
    })
    X_clf = data_clf[['x1', 'x2']].values
    y_clf = data_clf['y'].values
    
    perceptron_clf = Perceptron(input_size=2, activation='sigmoid')
    perceptron_clf.train(X_clf, y_clf)
    
    print("Classification Predictions:")
    for sample in X_clf:
        print(f"Input: {sample}, Predicted: {perceptron_clf.predict(sample)}")
```

---

## What This Code Does
1. **Trains a Perceptron for Regression** using Linear activation.
2. **Trains a Perceptron for Classification** using Sigmoid activation.
3. **Predicts outputs** for both cases.

---

## Summary
✅ The Perceptron can be used for **Regression (predicting numbers)** or **Classification (yes/no decisions)**.
✅ It uses **Linear Activation for Regression** and **Sigmoid Activation for Classification**.
✅ It learns using **Gradient Descent** to improve over time.
✅ Our example evaluates performance on both problems.

